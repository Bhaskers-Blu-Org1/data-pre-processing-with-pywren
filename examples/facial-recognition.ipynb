{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\"> Face Recognition Deep Learning with PyWren over IBM Cloud Functions</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains steps and code to demonstrate how serverless computing can provide great benefit for AI data preprocessing. We demonstrate face recognition using deep learning over the Watson Machine Learning service, while letting IBM Cloud Functions do the data preparation phase. As we will show this makes an entire process up to 50 times faster comparing to running the same code without leveraging serverless computing.\n",
    "\n",
    "Our notebook is based on a blog <a href=\"https://hackernoon.com/building-a-facial-recognition-pipeline-with-deep-learning-in-tensorflow-66e7645015b8\" target=\"_blank\" rel=\"noopener no referrer\">Building a Facial Recognition Pipeline with Deep Learning in Tensorflow</a> written by Cole Murray who kindly allowed us to use code and text from his blog.\n",
    "\n",
    "This notebook introduces commands for interacting with your Watson Machine Learning service such as uploading training definitions and kicking off a training session.\n",
    "\n",
    "Some familiarity with Python is helpful. This notebook uses:\n",
    "\n",
    "- Python 3 \n",
    "- <a href=\"https://dataplatform.cloud.ibm.com/docs/content/analyze-data/environments-parent.html\" target=\"_blank\" rel=\"noopener no referrer\">Watson Studio environments.</a>\n",
    "- <a href=\"https://cloud.ibm.com/openwhisk\" target=\"_blank\" rel=\"noopener no referrer\">IBM Cloud Functions</a>\n",
    "- <a href=\"https://github.com/pywren/pywren-ibm-cloud\" target=\"_blank\" rel=\"noopener no referrer\">PyWren for IBM Cloud</a>\n",
    "\n",
    "\n",
    "\n",
    "## Learning goals\n",
    "\n",
    "In this notebook, you will learn:\n",
    "\n",
    "-  How IBM Cloud Functions can be used for the data preparation phase\n",
    "-  The value of PyWren for IBM Cloud\n",
    "-  How to work with Watson Machine Learning to train Deep Learning models (TensorFlow + scikit-learn)\n",
    "-  How to retrieve and use models trained in WML\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Set up related IBM Cloud Services](#setup)\n",
    "2. [Dependencies installation](#dependencies-install)\n",
    "3. [Configuration](#configuration)\n",
    "4. [Preprocessing Data using Dlib and Docker](#preprocessing)\n",
    "5. [Setup for WML](#wml-setup)\n",
    "6. [Create the training definitions](#training-definitions)\n",
    "7. [Train the model](#train)\n",
    "8. [Work with the Trained Model](#work)\n",
    "9. [Summary](#summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "## <span style=\"color:blue\">1. Set up related IBM Cloud Services</span>\n",
    "\n",
    "Before you use the sample code in this notebook, you must setup Watson Machine Learning Service, IBM Cloud Object Storage and IBM Cloud Functions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Create Watson Machine Learning Service\n",
    "\n",
    "Create a <a href=\"https://console.ng.bluemix.net/catalog/services/ibm-watson-machine-learning/\" target=\"_blank\" rel=\"noopener no referrer\">Watson Machine Learning (WML) Service</a> instance (a free plan is offered and information about how to create the instance is <a href=\"https://dataplatform.ibm.com/docs/content/analyze-data/wml-setup.html\" target=\"_blank\" rel=\"noopener no referrer\">here</a>)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Create IBM Cloud Object Storage\n",
    "\n",
    "Create a <a href=\"https://console.bluemix.net/catalog/infrastructure/cloud-object-storage\" target=\"_blank\" rel=\"noopener no referrer\">Cloud Object Storage (COS)</a> instance (a lite plan is offered and information about how to order storage is <a href=\"https://console.bluemix.net/docs/services/cloud-object-storage/basics/order-storage.html#order-storage\" target=\"_blank\" rel=\"noopener no referrer\">here</a>). <br/>**Note: When using Watson Studio, you already have a COS instance associated with the project you are running the notebook in.**\n",
    "\n",
    "- Create new credentials with HMAC: \n",
    "    - Go to your COS dashboard.\n",
    "    - In the **Service credentials** tab, click **New Credential+**.\n",
    "    - Add the inline configuration parameter: {\"HMAC\":true}, click **Add**. (For more information, see <a href=\"https://console.bluemix.net/docs/services/cloud-object-storage/hmac/credentials.html#using-hmac-credentials\" target=\"_blank\" rel=\"noopener no referrer\">HMAC</a>.)\n",
    "\n",
    "    This configuration parameter adds the following section to the instance credentials, (for use later in this notebook):\n",
    "    ```\n",
    "      \"cos_hmac_keys\": {\n",
    "            \"access_key_id\": \"-------\",\n",
    "            \"secret_access_key\": \"-------\"\n",
    "       }\n",
    "    ```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Create IBM Cloud Functions account\n",
    "Setup IBM Cloud Functions account as described here. Please follow all the steps and make sure you can run the \"Hello World\" example based on Python code. This will assure your Cloud Functions service is running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"dependencies-install\"></a>\n",
    "## <span style=\"color:blue\"> 2. Dependencies installation </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the needed libraries for the face recognition preprocessing.\n",
    "The \"dlib\" dependency needs to be installed via new environment. Create a new environment based on Python 3.5 and add the dependency in the customization section as follows:\n",
    "\n",
    "    channels:\n",
    "    - conda-forge\n",
    "    dependencies:\n",
    "    - dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!curl -fsSL \"https://git.io/fhe9X\" | sh\n",
    "try:\n",
    "    import pywren_ibm_cloud as pywren\n",
    "except:\n",
    "    !curl -fsSL \"https://git.io/fhe9X\" | sh\n",
    "    import pywren_ibm_cloud as pywren\n",
    "try:\n",
    "    import cv2\n",
    "except:\n",
    "    !pip install --user opencv-contrib-python\n",
    "try:\n",
    "    from openface.align_dlib import AlignDlib\n",
    "except:    \n",
    "    !git clone https://github.com/cmusatyalab/openface.git\n",
    "    !cd openface ; python setup.py install\n",
    "\n",
    "from uuid import uuid4\n",
    "import bz2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"configuration\"></a>\n",
    "## <span style=\"color:blue\">3. Configuration </span>\n",
    "This section explains how to configure the needed services."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Setup a bucket in IBM Cloud Object Storage\n",
    "\n",
    "You need an IBM COS bucket which you will use to store the input data. If you don't know of any of your existing buckets or would like like to create a new one, please navigate to your <a href=\"https://cloud.ibm.com/resources\" target=\"_blank\" rel=\"noopener no referrer\">cloud resource list</a>,  then find and select your storage instance. From here, you will be able to view all your buckets and can create a new bucket in the region you prefer. Make sure you copy the correct endpoint for the bucket from the `Endpoint` tab of this COS service dashboard.\n",
    "\n",
    "**Note:** The bucket names must be unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill here the bucket name you created in COS Dashboard \n",
    "BUCKET = 'pywren-bucket-for-*****'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define COS endpoint information. Example of US Cross Region endpoint\n",
    "cos_endpoint = 'https://s3.us.cloud-object-storage.appdomain.cloud'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 COS Connection\n",
    "Now connect to the Cloud Object Storage service by first obtaining your credentials.\n",
    "\n",
    "You can find COS credentials in your COS instance dashboard under the `Service credentials` tab.\n",
    "Note: the HMAC key, described in set up the environment is included in these credentials.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_credentials = {\n",
    "  \"apikey\": \"*****\",\n",
    "  \"cos_hmac_keys\": {\n",
    "    \"access_key_id\": \"*****\",\n",
    "    \"secret_access_key\": \"*****\"\n",
    "  },\n",
    "  \"endpoints\": \"https://cos-service.bluemix.net/endpoints\",\n",
    "  \"iam_apikey_description\": \"Auto generated apikey during resource-key operation for Instance - crn:v1:bluemix:public:cloud-object-storage:global:a/bc1bd51c396536dc7d5f81d5a4e19533:d4f4b869-d55a-4bba-8830-2b1120c022e1::\",\n",
    "  \"iam_apikey_name\": \"auto-generated-apikey-6c7a2087-d839-443c-8da6-d08e94c3aed1\",\n",
    "  \"iam_role_crn\": \"crn:v1:bluemix:public:iam::::serviceRole:Writer\",\n",
    "  \"iam_serviceid_crn\": \"crn:v1:bluemix:public:iam-identity::a/bc1bd51c396536dc7d5f81d5a4e19533::serviceid:ServiceId-8c8f555c-c67f-429c-9582-18e541424301\",\n",
    "  \"resource_instance_id\": \"crn:v1:bluemix:public:cloud-object-storage:global:a/bc1bd51c396536dc7d5f81d5a4e19533:d4f4b869-d55a-4bba-8830-2b1120c022e1::\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You also need the IBM Cloud authorization endpoint to be able to create COS resource object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the authorization endpoint.\n",
    "auth_endpoint = 'https://iam.bluemix.net/oidc/token'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the boto library if necessary. This library allows Python developers to manage IBM Cloud Object Storage (COS). However, most environments on Watson Studio have this preinstalled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip:** If `ibm_boto3` is not preinstalled in you environment, run the following command to install it: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run the following command if ibm_boto3 is not installed.\n",
    "# !pip install ibm-cos-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the boto library.\n",
    "import ibm_boto3\n",
    "from ibm_botocore.client import Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Boto resource to be able to write data to COS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a COS resource.\n",
    "cos = ibm_boto3.resource('s3',\n",
    "                         ibm_api_key_id=cos_credentials['apikey'],\n",
    "                         ibm_service_instance_id=cos_credentials['resource_instance_id'],\n",
    "                         ibm_auth_endpoint=auth_endpoint,\n",
    "                         config=Config(signature_version='oauth'),\n",
    "                         endpoint_url=cos_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Verify you can access your COS Bucket\n",
    "\n",
    "If you fail to access your bucket, make sure you use the correct bucket name and endpoint URL for the region where the bucket was created. If you see no errors after running the following cell, you are good to go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: BUCKET\n",
    "except NameError: BUCKET = None\n",
    "\n",
    "if not BUCKET:\n",
    "    print (\"Error. Bucket can not be empty. Please create bucket in COS Dashboard UI and update 'BUCKET'\")\n",
    "\n",
    "try: cos\n",
    "except NameError: cos = None\n",
    "\n",
    "if not cos:\n",
    "    print(\"Error. Please create ibm_boto3 instance\")\n",
    "\n",
    "if cos and not cos.Bucket(BUCKET) in cos.buckets.all():\n",
    "    print (\"Error. Bucket not found. Please make sure cos_endpoint targets the region of the bucket\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 IBM Cloud Functions setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain the API key and endpoint to the <a href=\"https://cloud.ibm.com/openwhisk\" target=\"_blank\" rel=\"noopener no referrer\">IBM Cloud Functions service</a>. Navigate to `Getting Started` > `API Key` from the side menu and copy the values for \"Current Namespace\", \"Host\" and \"Key\" into the config below. Make sure to add \"https://\" to the host when adding it as the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "          'ibm_cf':  {'endpoint': 'https://openwhisk.ng.bluemix.net', \n",
    "                      'namespace': 'IBM Cloud Storage_dev', \n",
    "                      'api_key': '*****'}}\n",
    "config['ibm_cos'] = {}\n",
    "config['ibm_cos']['endpoint'] = cos_endpoint\n",
    "config['ibm_cos']['api_key'] = cos_credentials['apikey']\n",
    "config['pywren'] = {}\n",
    "config['pywren']['storage_bucket'] = BUCKET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PyWren engine requires its server side component to be deployed in advance. This step creates a new IBM Cloud Functions function with the PyWren server side runtime. This action will be used internally by PyWren during execution phases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning docker image ibmfunctions/pywren-dlib-runtime:3.5\n",
      "OK --> Updated action pywren-dlib-runtime_3.5\n",
      "OK --> Updated action pywren-dlib-runtime_3.5_modules\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "from pywren_ibm_cloud.deployutil import clone_runtime\n",
    "clone_runtime('ibmfunctions/pywren-dlib-runtime:3.5', config, 'pywren-ibm-cloud')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"preprocessing\"></a>\n",
    "## <span style=\"color:blue\">4. Preprocessing Data using Dlib and Docker</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Upload input data into IBM Cloud Object Storage\n",
    "\n",
    "Your COS Bucket should contain the raw dataset of images with the following structure:\n",
    "\n",
    "     Directory Structure\n",
    "     ├── Tyra_Banks\n",
    "     │ ├── Tyra_Banks_0001.jpg\n",
    "     │ └── Tyra_Banks_0002.jpg\n",
    "     ├── Tyron_Garner\n",
    "     │ ├── Tyron_Garner_0001.jpg\n",
    "     │ └── Tyron_Garner_0002.jpg\n",
    "     \n",
    "If you don't have any images, we will demonstrate how to use the [LFW](http://vis-www.cs.umass.edu/lfw/) (Labeled Faces in the Wild) dataset as training data. Below are instructions how you can upload this dataset into your private COS bucket.\n",
    "\n",
    "**You should run this only once. If images were already created in any previous run, you can skip this section.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following step copies images from Labeled Faces in the Wild into your COS bucket.\n",
    "We demonstrate with small data set of about 14MB. If you wish to use entire data set, then use \n",
    "\n",
    "    url = \"http://vis-www.cs.umass.edu/lfw/lfw.tgz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import tarfile\n",
    "import io\n",
    "from multiprocessing import Process \n",
    "\n",
    "def extractFromStream(url, cos, target_prefix = None):\n",
    "    procs = []\n",
    "    \n",
    "    def copy(target_key, member_like_object):        \n",
    "        cos.Object(BUCKET, key).put(Body=member_like_object.read())\n",
    "\n",
    "    ftp_stream = urllib.request.urlopen(url)\n",
    "    tarfile_like_object = io.BytesIO(ftp_stream.read())\n",
    "    TarFile_object = tarfile.open(fileobj=tarfile_like_object)\n",
    "    for member in TarFile_object:\n",
    "        if member.isdir() == False:\n",
    "            member_like_object = TarFile_object.extractfile(member)\n",
    "            #member.name has prefix 'lfw' and is of the form lfw/name_familyname/name_familyname_0001.jpg\n",
    "            #the following code removes prefix lfw from the name\n",
    "            candidate_key = member.name\n",
    "            if candidate_key.find(\"/\") >= 0:\n",
    "                ind = candidate_key.index(\"/\") + 1\n",
    "                candidate_key = candidate_key[ind:]\n",
    "\n",
    "            key = candidate_key\n",
    "            if target_prefix is not None:\n",
    "                key = target_prefix + '/' + candidate_key\n",
    "            #cos.Object(BUCKET, key).put(Body=member_like_object.read())\n",
    "            p = Process(target=copy, args=(key, member_like_object))\n",
    "            p.start()\n",
    "            procs.append(p)\n",
    "\n",
    "    for p in procs:\n",
    "        p.join()\n",
    "\n",
    "\n",
    "url = \"http://vis-www.cs.umass.edu/lfw/lfw-a.tgz\"\n",
    "extractFromStream(url, cos, \"images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pywren-bucket-for-richh-2 contains 1584 images\n"
     ]
    }
   ],
   "source": [
    "bucket = cos.Bucket(BUCKET)\n",
    "print(bucket.name + \" contains \" + str(len(list(bucket.objects.filter(Prefix='images')))) + \" images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Data preprocessing with serverless\n",
    "\n",
    "Below, you’ll preprocess the images before passing them into the FaceNet model. Image pre-processing in a facial recognition context typically solves a few problems. These problems range from lighting differences, occlusion, alignment, and segmentation. Below, you’ll address segmentation and alignment.\n",
    "\n",
    "First, you’ll solve the segmentation problem by finding the largest face in an image. This is useful as our training data does not have to be cropped for a face ahead of time.\n",
    "\n",
    "Second, you’ll solve alignment. In photographs, it is common for a face to not be perfectly center aligned with the image. To standardize input, you’ll apply a transform to center all images based on the location of eyes and bottom lip.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Detect, Crop & Align with Dlib\n",
    "\n",
    "Upload dlib’s face landmark predictor into your COS bucket. You’ll use this face landmark predictor to find the location of the inner eyes and bottom lips of a face in an image. These coordinates will be used to center align the image.\n",
    "\n",
    "**You should run this only once. If the predictor was already created in a previous run, you can skip this section.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import io\n",
    "\n",
    "def uploadFileFromStream(url, name, cos, target_prefix = None):\n",
    "    ftp_stream = urllib.request.urlopen(url + name)\n",
    "    file_like_object = io.BytesIO(ftp_stream.read())\n",
    "    src = bz2.BZ2File(file_like_object, \"rb\")\n",
    "    key = name[:-4]\n",
    "    if target_prefix is not None:\n",
    "        key = target_prefix + '/' + name[:-4]\n",
    "    cos.Object(BUCKET, key).put(Body=src.read())\n",
    "\n",
    "uploadFileFromStream(\"http://dlib.net/files/\", \"shape_predictor_68_face_landmarks.dat.bz2\", cos, 'predictor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Preprocessing with IBM Cloud Functions\n",
    "Next, you’ll create a preprocessor for your dataset. This file will read each image into memory, attempt to find the largest face, center align, and write the file to output. If a face cannot be found in the image, logging will be displayed to console with the filename.\n",
    "As each image can be processed independently, python’s multiprocessing is used to process an image on each available cpu core."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import time\n",
    "import pywren_ibm_cloud as pywren\n",
    "import shutil\n",
    "import cv2\n",
    "\n",
    "from openface.align_dlib import AlignDlib\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "temp_dir = '/tmp'\n",
    "\n",
    "def preprocess_image(bucket, key, data_stream, ibm_cos):\n",
    "    \"\"\"\n",
    "    Detect face, align and crop :param input_path. Write output to :param output_path\n",
    "    :param bucket: COS bucket\n",
    "    :param key: COS key (object name ) - may contain delimiters\n",
    "    :param storage_handler: can be used to read / write data from / into COS\n",
    "    \"\"\"\n",
    "    crop_dim = 180\n",
    "    print(\"Process bucket {} key {}\".format(bucket, key))    \n",
    "    # key of the form /subdir1/../subdirN/file_name\n",
    "    key_components = key.split('/')\n",
    "    file_name = key_components[len(key_components)-1]\n",
    "    input_path = temp_dir + '/' + file_name\n",
    "    if not os.path.exists(temp_dir + '/' + 'output'):\n",
    "        os.makedirs(temp_dir + '/' +'output')\n",
    "    output_path = temp_dir + '/' +'output/'  + file_name\n",
    "    with open(input_path, 'wb') as localfile:\n",
    "        shutil.copyfileobj(data_stream, localfile)\n",
    "    exists = os.path.isfile(temp_dir + '/' +'shape_predictor_68_face_landmarks')\n",
    "    if exists:\n",
    "        pass;\n",
    "    else:\n",
    "        res = ibm_cos.get_object(Bucket = bucket, Key = 'predictor/shape_predictor_68_face_landmarks.dat')\n",
    "        with open(temp_dir + '/' +'shape_predictor_68_face_landmarks', 'wb') as localfile:\n",
    "            shutil.copyfileobj(res['Body'], localfile)\n",
    "    align_dlib = AlignDlib(temp_dir + '/' +'shape_predictor_68_face_landmarks')\n",
    "    image = _process_image(input_path, crop_dim, align_dlib)\n",
    "    if image is not None:\n",
    "        print('Writing processed file: {}'.format(output_path))\n",
    "        cv2.imwrite(output_path, image)\n",
    "        f = open(output_path, \"rb\")\n",
    "        processed_image_path = os.path.join('output',key)\n",
    "        ibm_cos.put_object(Bucket = bucket, Key = processed_image_path, Body = f)\n",
    "        os.remove(output_path)\n",
    "    else:\n",
    "        print(\"Skipping filename: {}\".format(input_path))\n",
    "    os.remove(input_path)\n",
    "\n",
    "def _process_image(filename, crop_dim, align_dlib):\n",
    "    image = None\n",
    "    aligned_image = None\n",
    "    image = _buffer_image(filename)\n",
    "    if image is not None:\n",
    "        aligned_image = _align_image(image, crop_dim, align_dlib)\n",
    "    else:\n",
    "        raise IOError('Error buffering image: {}'.format(filename))\n",
    "    return aligned_image\n",
    "\n",
    "def _buffer_image(filename):\n",
    "    logger.debug('Reading image: {}'.format(filename))\n",
    "    image = cv2.imread(filename, )\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image\n",
    "\n",
    "def _align_image(image, crop_dim, align_dlib):\n",
    "    bb = align_dlib.getLargestFaceBoundingBox(image)\n",
    "    aligned = align_dlib.align(crop_dim, image, bb, landmarkIndices=AlignDlib.INNER_EYES_AND_BOTTOM_LIP)\n",
    "    if aligned is not None:\n",
    "        aligned = cv2.cvtColor(aligned, cv2.COLOR_BGR2RGB)\n",
    "    return aligned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Getting Results\n",
    "\n",
    "Now that you’ve created a pipeline, time to get results. As the script supports parallelism, you will see increased performance by running with multiple cores. You’ll need to run the preprocessor in the docker environment to have access to the installed libraries.\n",
    "Below, you’ll mount your project directory as a volume inside the docker container and run the preprocessing script on your input data. The results will be written to a directory specified with command line arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IBM Cloud Functions init for pywren-dlib-runtime_3.5\n",
      "IBM Cloud Functions executor created with ID e47f0687-724a\n",
      "Executor ID e47f0687-724a Uploading function and data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    0%|          | 0/1  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor ID e47f0687-724a Starting function invocation: preprocess_image()\n",
      "Executor ID e47f0687-724a Function 00000 - Activation ID: 486c7793e77443acac7793e77473ac99 - Time: 0.106 seconds\n",
      "Executor ID e47f0687-724a Invocation done: 0.128 seconds\n",
      "Executor ID e47f0687-724a Getting results\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  100%|██████████| 1585/1585  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution completed\n",
      "Executor ID e47f0687-724a Cleaning partial results from bucket 'pywren-bucket-for-richh-2' and prefix 'pywren.jobs/e47f0687-724a'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "raw_images = BUCKET + '/images'\n",
    "pw = pywren.ibm_cf_executor(config=config, runtime='pywren-dlib-runtime_3.5')\n",
    "try:\n",
    "    pw.map(preprocess_image, raw_images, remote_invocation=True)\n",
    "    results = pw.get_result()\n",
    "    print(\"Execution completed\")\n",
    "except Exception as e:\n",
    "    print (e)\n",
    "finally:    \n",
    "    pw.clean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review\n",
    "\n",
    "Using Dlib, you detected the largest face in an image and aligned the center of the face by the inner eyes and bottom lip. This alignment is a method for standardizing each image for use as feature input.\n",
    "\n",
    "Verify that images were processed with dlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1579 images were pre-processed with dlib\n",
      "COS location of pre-processed images is: pywren-bucket-for-richh-2/output/images/\n"
     ]
    }
   ],
   "source": [
    "bucket = cos.Bucket(BUCKET)\n",
    "print(str(len(list(bucket.objects.filter(Prefix='output/images')))) + \" images were pre-processed with dlib\")\n",
    "print (\"COS location of pre-processed images is: \" + bucket.name + '/output/images/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"wml-setup\"></a>\n",
    "## <span style=\"color:blue\">5. Setup for WML</span>\n",
    "\n",
    "Now that we've preprocessed the data, we’ll generate vector embeddings of each identity. These embeddings can then be used as input to a classification, regression, or clustering task. We will use TensorFlow to create the embeddings and then scikit-learn to create the classifier with these embeddings. However, before we do all this, some preliminary setup is needed.\n",
    "\n",
    "In this section we:\n",
    "\n",
    "- [5.1 Download Pretrained Model](#download-model)\n",
    "- [5.2 Save model files to Cloud Object Storage](#save-model-cos)\n",
    "- [5.3 Authenticate with the WML service instance](#wml-service-instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Download pretrained model<a id=\"download-model\"></a>\n",
    "\n",
    "We will use a pretrained model to simplify the process of generating the embeddings. The model we will use is based off the Inception ResNet V1 architecture and was trained using the <a href=\"http://www.robots.ox.ac.uk/~vgg/data/vgg_face2/\" target=\"_blank\" rel=\"noopener no referrer\">VGGFace2</a> dataset. With the pretrained model and its learned weights, we can use transfer learning in order to create a model that can classify the LFW faces.\n",
    "\n",
    "First, we download and extract the pretrained model using a script copied from <a href=\"https://github.com/davidsandberg/facenet/blob/master/src/download_and_extract.py\" target=\"_blank\" rel=\"noopener no referrer\">here</a>: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "\"\"\"\n",
    "This file is copied and adapted from:\n",
    "https://github.com/davidsandberg/facenet/blob/master/src/download_and_extract.py\n",
    "\"\"\"\n",
    "\n",
    "model_dict = {\n",
    "    '20180402-114759': '1EXPBSXwTaqrSC0OhUdXNmKSh9qJUQ55-'\n",
    "}\n",
    "\n",
    "def download_and_extract_file(model_name, data_dir):\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "\n",
    "    file_id = model_dict[model_name]\n",
    "    destination = os.path.join(data_dir, model_name + '.zip')\n",
    "    if not os.path.exists(destination):\n",
    "        print('Downloading file to %s' % destination)\n",
    "        download_file_from_google_drive(file_id, destination)\n",
    "        with zipfile.ZipFile(destination, 'r') as zip_ref:\n",
    "            print('Extracting file to %s' % data_dir)\n",
    "            zip_ref.extractall(data_dir)\n",
    "\n",
    "def download_file_from_google_drive(file_id, destination):\n",
    "\n",
    "        URL = \"https://drive.google.com/uc?export=download\"\n",
    "        session = requests.Session()\n",
    "        response = session.get(URL, params = { 'id' : file_id }, stream = True)\n",
    "        token = get_confirm_token(response)\n",
    "\n",
    "        if token:\n",
    "            params = { 'id' : file_id, 'confirm' : token }\n",
    "            response = session.get(URL, params = params, stream = True)\n",
    "\n",
    "        save_response_content(response, destination)\n",
    "\n",
    "def get_confirm_token(response):\n",
    "    for key, value in response.cookies.items():\n",
    "        if key.startswith('download_warning'):\n",
    "            return value\n",
    "    return None\n",
    "\n",
    "def save_response_content(response, destination):\n",
    "    CHUNK_SIZE = 32768\n",
    "\n",
    "    with open(destination, \"wb\") as f:\n",
    "        for chunk in response.iter_content(CHUNK_SIZE):\n",
    "            if chunk: # filter out keep-alive new chunks\n",
    "                f.write(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initiate the download\n",
    "\n",
    "The download is about 184Mb in size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading file to ./pretrained-model/20180402-114759.zip\n",
      "Extracting file to ./pretrained-model\n"
     ]
    }
   ],
   "source": [
    "download_and_extract_file('20180402-114759', './pretrained-model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Save model files to Cloud Object Storage <a id=\"save-model-cos\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have another bucket you want to save the model files to, set it here,\n",
    "# otherwise we will use the same bucket.\n",
    "\n",
    "# BUCKET = ''\n",
    "bucket_obj = cos.Bucket(BUCKET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading data pretrained-model/model-20180402-114759.meta...\n",
      "pretrained-model/model-20180402-114759.meta is uploaded.\n",
      "Uploading data pretrained-model/20180402-114759.pb...\n",
      "pretrained-model/20180402-114759.pb is uploaded.\n",
      "Uploading data pretrained-model/model-20180402-114759.ckpt-275.index...\n",
      "pretrained-model/model-20180402-114759.ckpt-275.index is uploaded.\n",
      "Uploading data pretrained-model/model-20180402-114759.ckpt-275.data-00000-of-00001...\n",
      "pretrained-model/model-20180402-114759.ckpt-275.data-00000-of-00001 is uploaded.\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "files_search = os.path.join('./pretrained-model/*/*')\n",
    "files = glob.glob(files_search)\n",
    "\n",
    "\n",
    "for file in files:\n",
    "    filename = file.split('/')[-1]\n",
    "    filename = os.path.join(\"pretrained-model\", filename)\n",
    "    print('Uploading data {}...'.format(filename))\n",
    "    bucket_obj.upload_file(file, filename )\n",
    "    print('{} is uploaded.'.format(filename))\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Authenticate with the WML service instance <a id=\"wml-service-instance\"></a>\n",
    "\n",
    "Import the libraries you need to work with your WML instance.\n",
    "\n",
    "**Hint**: You may also need to install `wget` using the following command `!pip install wget`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wget\n",
      "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
      "Building wheels for collected packages: wget\n",
      "  Running setup.py bdist_wheel for wget ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/dsxuser/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
      "Successfully built wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3, requests, json, base64, time, os, wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authenticate to the Watson Machine Learning (WML) service on IBM Cloud.\n",
    "\n",
    "**Tip**: Authentication information (your credentials) can be found in the <a href=\"https://console.bluemix.net/docs/services/service_credentials.html#service_credentials\" target=\"_blank\" rel=\"noopener noreferrer\">Service credentials</a> tab of the service instance that you created on IBM Cloud. \n",
    "If there are no credentials listed for your instance in **Service credentials**, click **New credential (+)** and enter the information required to generate new authentication information. \n",
    "\n",
    "**Action**: Enter your WML service instance credentials here.\n",
    "\n",
    "`\n",
    "wml_credentials = {\n",
    "  \"apikey\": \"------\",\n",
    "  \"iam_apikey_description\": \"------:\",\n",
    "  \"iam_apikey_name\": \"------\",\n",
    "  \"iam_role_crn\": \"-------\",\n",
    "  \"iam_serviceid_crn\": \"-------\",\n",
    "  \"instance_id\": \"-------\",\n",
    "  \"password\": \"------\",\n",
    "  \"url\": \"------\",\n",
    "  \"username\": \"-------\"\n",
    "}\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @hidden_cell\n",
    "wml_credentials = {\n",
    "  \"apikey\": \"*****\",\n",
    "  \"iam_apikey_description\": \"Auto generated apikey during resource-key operation for Instance - crn:v1:bluemix:public:pm-20:us-south:a/bc1bd51c396536dc7d5f81d5a4e19533:a8ab45b5-055a-40d9-8418-0b26bae17433::\",\n",
    "  \"iam_apikey_name\": \"auto-generated-apikey-8d0c1b72-1bf6-40b9-824d-06ea3a67f148\",\n",
    "  \"iam_role_crn\": \"crn:v1:bluemix:public:iam::::serviceRole:Writer\",\n",
    "  \"iam_serviceid_crn\": \"crn:v1:bluemix:public:iam-identity::a/bc1bd51c396536dc7d5f81d5a4e19533::serviceid:ServiceId-22ebfeae-7e29-45ff-8c5f-097f6537858e\",\n",
    "  \"instance_id\": \"a8ab45b5-055a-40d9-8418-0b26bae17433\",\n",
    "  \"password\": \"*****\",\n",
    "  \"url\": \"https://us-south.ml.cloud.ibm.com\",\n",
    "  \"username\": \"*****\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the `watson-machine-learning-client` and authenticate to the service instance.\n",
    "\n",
    "**Tip:** If `watson-machine-learning-client` is not preinstalled in your environment, run the following command to install it: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement not upgraded as not directly required: watson-machine-learning-client in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages\n",
      "Requirement not upgraded as not directly required: certifi in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from watson-machine-learning-client)\n",
      "Requirement not upgraded as not directly required: tabulate in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from watson-machine-learning-client)\n",
      "Requirement not upgraded as not directly required: tqdm in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from watson-machine-learning-client)\n",
      "Requirement not upgraded as not directly required: ibm-cos-sdk in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from watson-machine-learning-client)\n",
      "Requirement not upgraded as not directly required: pandas in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from watson-machine-learning-client)\n",
      "Requirement not upgraded as not directly required: requests in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from watson-machine-learning-client)\n",
      "Requirement not upgraded as not directly required: lomond in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from watson-machine-learning-client)\n",
      "Requirement not upgraded as not directly required: urllib3 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from watson-machine-learning-client)\n",
      "Requirement not upgraded as not directly required: ibm-cos-sdk-core==2.*,>=2.0.0 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from ibm-cos-sdk->watson-machine-learning-client)\n",
      "Requirement not upgraded as not directly required: ibm-cos-sdk-s3transfer==2.*,>=2.0.0 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from ibm-cos-sdk->watson-machine-learning-client)\n",
      "Requirement not upgraded as not directly required: python-dateutil>=2 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from pandas->watson-machine-learning-client)\n",
      "Requirement not upgraded as not directly required: pytz>=2011k in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from pandas->watson-machine-learning-client)\n",
      "Requirement not upgraded as not directly required: numpy>=1.9.0 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from pandas->watson-machine-learning-client)\n",
      "Requirement not upgraded as not directly required: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from requests->watson-machine-learning-client)\n",
      "Requirement not upgraded as not directly required: idna<2.7,>=2.5 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from requests->watson-machine-learning-client)\n",
      "Requirement not upgraded as not directly required: six>=1.10.0 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from lomond->watson-machine-learning-client)\n",
      "Requirement not upgraded as not directly required: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from ibm-cos-sdk-core==2.*,>=2.0.0->ibm-cos-sdk->watson-machine-learning-client)\n",
      "Requirement not upgraded as not directly required: docutils>=0.10 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from ibm-cos-sdk-core==2.*,>=2.0.0->ibm-cos-sdk->watson-machine-learning-client)\n"
     ]
    }
   ],
   "source": [
    "!pip install watson-machine-learning-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from watson_machine_learning_client import WatsonMachineLearningAPIClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** A deprecation warning may be returned from scikit-learn package that does not impact watson machine learning client functionalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.351\n"
     ]
    }
   ],
   "source": [
    "client = WatsonMachineLearningAPIClient(wml_credentials)\n",
    "print(client.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"training-definitions\"></a>\n",
    "## <span style=\"color:blue\">6. Create the training definitions</span>\n",
    "\n",
    "With us now connected to our WML service instance, we can now create the training definitions.\n",
    "\n",
    "In this section you:\n",
    "\n",
    "- [6.1 Prepare the training definition metadata](#prep)\n",
    "- [6.2 Get the sample model definition content files from Git](#get)\n",
    "- [6.3 Store the training definition in the WML repository](#store)\n",
    "\n",
    "**Note:** `watson-machine-learning-client` documentation can be found <a href=\"http://wml-api-pyclient.mybluemix.net/\" target=\"_blank\" rel=\"noopener noreferrer\">here</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Prepare the training definition metadata<a id=\"prep\"></a>\n",
    "\n",
    "Prepare the training definition metadata. The main program will use the\n",
    "enviroment variables `$DATA_DIR` and `$RESULT_DIR` in the inputs for the\n",
    "`--model-path`, `--input-dir`, and `--output-path` options.\n",
    "\n",
    "**Tip:** You may want to change the number of epochs to be larger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_definition_metadata = {\n",
    "    client.repository.DefinitionMetaNames.NAME: \"TensorFlow Facial Recognition\",\n",
    "    client.repository.DefinitionMetaNames.DESCRIPTION: \"Face Classifier\",\n",
    "    client.repository.DefinitionMetaNames.AUTHOR_NAME: \"IBM Developer\",\n",
    "    client.repository.DefinitionMetaNames.FRAMEWORK_NAME: \"tensorflow\",\n",
    "    client.repository.DefinitionMetaNames.FRAMEWORK_VERSION: \"1.11\",\n",
    "    client.repository.DefinitionMetaNames.RUNTIME_NAME: \"python\",\n",
    "    client.repository.DefinitionMetaNames.RUNTIME_VERSION: \"3.6\",\n",
    "    client.repository.DefinitionMetaNames.EXECUTION_COMMAND: \" \\\n",
    "        python3 train_classifier.py \\\n",
    "            --model-path $DATA_DIR/pretrained-model/20180402-114759.pb \\\n",
    "            --input-dir $DATA_DIR/output/images \\\n",
    "            --output-path $RESULT_DIR/output-classifier.pkl \\\n",
    "            --num-epochs 3\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Get the sample model definition content file from GitHub <a id=\"get\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf-facial-recog.zip was downloaded\n"
     ]
    }
   ],
   "source": [
    "filename='tf-facial-recog.zip'\n",
    "\n",
    "if not os.path.isfile(filename):\n",
    "    filename = wget.download('https://github.com/IBM/data-pre-processing-with-pywren/raw/master/data/code/tf-facial-recog.zip')\n",
    "    print(filename, \"was downloaded\")\n",
    "else:\n",
    "    print(filename, \"was downloaded previously.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files in this zip file can be viewed in the GitHub <a href=\"https://github.com/IBM/data-pre-processing-with-pywren/tree/master/data/code\" target=\"_blank\" rel=\"noopener noreferrer\">repository</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Store the training definition in the WML repository<a id=\"store\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7d825597-7e30-47ed-a6fb-2878da06c611\n"
     ]
    }
   ],
   "source": [
    "definition_details = client.repository.store_definition(filename, training_definition_metadata)\n",
    "definition_uid = client.repository.get_definition_uid(definition_details)\n",
    "\n",
    "# Display the training definition uid.\n",
    "print(definition_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">7. Train the model</span><a id=\"train\"></a>\n",
    "\n",
    "In this section, learn how to:\n",
    "- [7.1 Enter training configuration metadata](#meta)\n",
    "- [7.2 Train the model in the background](#backg)\n",
    "- [7.3 Monitor the training log](#log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Enter training configuration metadata<a id=\"meta\"></a>\n",
    "\n",
    "- `TRAINING_DATA_REFERENCE` - references the uploaded training data.\n",
    "- `TRAINING_RESULTS_REFERENCE` - location where trained model will be saved.\n",
    "\n",
    "For this exercise, we are going to use the same bucket as the input data to store our resulting model.\n",
    "\n",
    "**Note** Your COS credentials are referenced in this code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the training metadata for the TRAINING_DATA_REFERENCE and TRAINING_RESULTS_REFERENCE.\n",
    "training_configuration_metadata = {\n",
    "    client.training.ConfigurationMetaNames.NAME: \"Face Classifier\", \n",
    "    client.training.ConfigurationMetaNames.AUTHOR_NAME: \"IBM Developer\",              \n",
    "    client.training.ConfigurationMetaNames.DESCRIPTION: \"Training for Face Classifier\",\n",
    "    client.training.ConfigurationMetaNames.COMPUTE_CONFIGURATION: {\"name\": \"k80\"},\n",
    "    client.training.ConfigurationMetaNames.TRAINING_DATA_REFERENCE: {\n",
    "        \"connection\": {\n",
    "            \"endpoint_url\": cos_endpoint,\n",
    "            \"access_key_id\": cos_credentials['cos_hmac_keys']['access_key_id'],\n",
    "            \"secret_access_key\": cos_credentials['cos_hmac_keys']['secret_access_key']\n",
    "        },\n",
    "        \"source\": {\n",
    "            \"bucket\": BUCKET,\n",
    "        },\n",
    "        \"type\": \"s3\"\n",
    "    },\n",
    "    client.training.ConfigurationMetaNames.TRAINING_RESULTS_REFERENCE: {\n",
    "        \"connection\": {\n",
    "            \"endpoint_url\": cos_endpoint,\n",
    "            \"access_key_id\": cos_credentials['cos_hmac_keys']['access_key_id'],\n",
    "            \"secret_access_key\": cos_credentials['cos_hmac_keys']['secret_access_key']\n",
    "        },\n",
    "        \"target\": {\n",
    "            \"bucket\": BUCKET,\n",
    "        },\n",
    "        \"type\": \"s3\"\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Train the model in the background<a id=\"backg\"></a>\n",
    "\n",
    "To run the training in the **background**, set the optional parameter `asynchronous=True` (or remove it). In this case the parameter has been removed. \n",
    "\n",
    "**Note:** To run the training in **active** mode, set `asynchronous=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the training run.\n",
    "training_run_details = client.training.run(definition_uid, training_configuration_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the power of WML, the embedding creation and subsequent training should be relatively quick.\n",
    "While training, we will be applying additional random transformations and augmentations to the images, boosting our dataset. These images will be fed in a batch size of 128 into the model, and the model will return a 512 dimensional embedding for each image. After these embeddings are created, they will be used as feature inputs into a scikit-learn’s SVM classifier to train on each class. Classes with less than 10 images will be dropped. This parameter is tunable in the execution command specified in the `training_definition_metadata` dictionary above.\n",
    "\n",
    "Get the training run GUID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_run_guid_async= model-xnq63yp8\n"
     ]
    }
   ],
   "source": [
    "training_run_guid_async = client.training.get_run_uid(training_run_details)\n",
    "print(\"training_run_guid_async=\",training_run_guid_async)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the status of the training run by calling the following method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"metrics\": [],\n",
      "  \"current_at\": \"2019-01-30T23:04:22Z\",\n",
      "  \"state\": \"pending\",\n",
      "  \"submitted_at\": \"2019-01-30T23:04:10Z\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Get training run status.\n",
    "status = client.training.get_status(training_run_guid_async)\n",
    "print(json.dumps(status, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3  Monitor the training log<a id=\"log\"></a>\n",
    "\n",
    "Run the cell below to monitor the training log. This will continue monitoring until the run is finished. If you wish to stop monitoring a current training run, click on the stop button next to \"Run\" button at the top in the notebook options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "####################################################\n",
      "\n",
      "Log monitor started for training run: model-xnq63yp8\n",
      "\n",
      "####################################################\n",
      "\n",
      "\n",
      "training-yymFH-_ig: \n",
      "training-yymFH-_ig: \n",
      "training-yymFH-_ig: \n",
      "training-yymFH-_ig: \n",
      "training-yymFH-_ig: \n",
      "training-yymFH-_ig: \n",
      "training-yymFH-_ig: \n",
      "training-yymFH-_ig: \n",
      "training-yymFH-_ig: \n",
      "training-yymFH-_ig: \n",
      "training-yymFH-_ig: \n",
      "training-yymFH-_ig: \n",
      "training-yymFH-_ig: \n",
      "training-yymFH-_ig: \n",
      "training-yymFH-_ig: \n",
      "training-yymFH-_ig: \n",
      "training-yymFH-_ig: \n",
      "training-yymFH-_ig: \n",
      "training-yymFH-_ig: Training with training/test data at:\n",
      "\n",
      "training-yymFH-_ig:   DATA_DIR: /mnt/data/pywren-bucket-for-richh-2\n",
      "\n",
      "training-yymFH-_ig:   MODEL_DIR: /job/model-code\n",
      "\n",
      "training-yymFH-_ig:   TRAINING_JOB: \n",
      "\n",
      "training-yymFH-_ig:   TRAINING_COMMAND:          python3 train_classifier.py             --model-path $DATA_DIR/pretrained-model/20180402-114759.pb             --input-dir $DATA_DIR/output/images             --output-path $RESULT_DIR/output-classifier.pkl             --num-epochs 3\n",
      "\n",
      "training-yymFH-_ig: Storing trained model at:\n",
      "\n",
      "training-yymFH-_ig:   RESULT_DIR: /mnt/results/pywren-bucket-for-richh-2/training-yymFH-_ig\n",
      "\n",
      "training-yymFH-_ig: Wed Jan 30 23:08:17 UTC 2019: Running Tensorflow job\n",
      "\n",
      "training-yymFH-_ig: \n",
      "training-yymFH-_ig: \n",
      "training-yymFH-_ig: \n",
      "training-yymFH-_ig: \n",
      "training-yymFH-_ig: \n",
      "training-yymFH-_ig: \n",
      "training-yymFH-_ig: \n",
      "training-yymFH-_ig: \n",
      "training-yymFH-_ig: \n",
      "training-yymFH-_ig: \n",
      "training-yymFH-_ig: \n",
      "training-yymFH-_ig: \n",
      "training-yymFH-_ig: \n",
      "training-yymFH-_ig: \n",
      "training-yymFH-_ig: /opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\n",
      "training-yymFH-_ig:   from ._conv import register_converters as _register_converters\n",
      "\n",
      "training-yymFH-_ig: INFO:input_loader:Skipped 417 classes which had less than 10 images.\n",
      "\n",
      "training-yymFH-_ig: INFO:__main__:Creating embeddings for training set.\n",
      "\n",
      "training-yymFH-_ig: 2019-01-30 23:10:38.902694: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\n",
      "training-yymFH-_ig: 2019-01-30 23:10:39.126718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: \n",
      "\n",
      "training-yymFH-_ig: name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "\n",
      "training-yymFH-_ig: pciBusID: 0000:83:00.0\n",
      "\n",
      "training-yymFH-_ig: totalMemory: 11.17GiB freeMemory: 10.88GiB\n",
      "\n",
      "training-yymFH-_ig: 2019-01-30 23:10:39.126765: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\n",
      "\n",
      "training-yymFH-_ig: 2019-01-30 23:10:39.431240: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "\n",
      "training-yymFH-_ig: 2019-01-30 23:10:39.431287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 \n",
      "\n",
      "training-yymFH-_ig: 2019-01-30 23:10:39.431294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N \n",
      "\n",
      "training-yymFH-_ig: 2019-01-30 23:10:39.431611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10541 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:83:00.0, compute capability: 3.7)\n",
      "\n",
      "training-yymFH-_ig: INFO:root:Model filename: /mnt/data/pywren-bucket-for-richh-2/pretrained-model/20180402-114759.pb\n",
      "\n",
      "training-yymFH-_ig: \n",
      "training-yymFH-_ig: INFO:__main__:Processing iteration 0 batch of size: 128\n",
      "\n",
      "training-yymFH-_ig: INFO:__main__:Processing iteration 1 batch of size: 128\n",
      "\n",
      "training-yymFH-_ig: INFO:__main__:Processing iteration 2 batch of size: 128\n",
      "\n",
      "training-yymFH-_ig: INFO:__main__:Processing iteration 3 batch of size: 128\n",
      "\n",
      "training-yymFH-_ig: \n",
      "training-yymFH-_ig: INFO:__main__:Processing iteration 4 batch of size: 128\n",
      "\n",
      "training-yymFH-_ig: INFO:__main__:Processing iteration 5 batch of size: 128\n",
      "\n",
      "training-yymFH-_ig: INFO:__main__:Processing iteration 6 batch of size: 128\n",
      "\n",
      "training-yymFH-_ig: INFO:__main__:Processing iteration 7 batch of size: 128\n",
      "\n",
      "training-yymFH-_ig: INFO:__main__:Processing iteration 8 batch of size: 128\n",
      "\n",
      "training-yymFH-_ig: INFO:__main__:Processing iteration 9 batch of size: 128\n",
      "\n",
      "training-yymFH-_ig: INFO:__main__:Processing iteration 10 batch of size: 128\n",
      "\n",
      "training-yymFH-_ig: INFO:__main__:Processing iteration 11 batch of size: 128\n",
      "\n",
      "training-yymFH-_ig: INFO:__main__:Processing iteration 12 batch of size: 128\n",
      "\n",
      "training-yymFH-_ig: \n",
      "training-yymFH-_ig: INFO:__main__:Processing iteration 13 batch of size: 128\n",
      "\n",
      "training-yymFH-_ig: INFO:__main__:Processing iteration 14 batch of size: 101\n",
      "\n",
      "training-yymFH-_ig: INFO:__main__:Created 1893 embeddings\n",
      "\n",
      "training-yymFH-_ig: INFO:__main__:Training Classifier\n",
      "\n",
      "training-yymFH-_ig: INFO:root:Saved classifier model to file \"/mnt/results/pywren-bucket-for-richh-2/training-yymFH-_ig/output-classifier.pkl\"\n",
      "\n",
      "training-yymFH-_ig: INFO:__main__:Training completed in 179.47856545448303 seconds\n",
      "\n",
      "training-yymFH-_ig: INFO:__main__:Creating embeddings for test set.\n",
      "\n",
      "training-yymFH-_ig: 2019-01-30 23:11:18.678048: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\n",
      "\n",
      "training-yymFH-_ig: 2019-01-30 23:11:18.678167: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "\n",
      "training-yymFH-_ig: 2019-01-30 23:11:18.678189: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 \n",
      "\n",
      "training-yymFH-_ig: 2019-01-30 23:11:18.678203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N \n",
      "\n",
      "training-yymFH-_ig: 2019-01-30 23:11:18.678726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10541 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:83:00.0, compute capability: 3.7)\n",
      "\n",
      "training-yymFH-_ig: INFO:root:Model filename: /mnt/data/pywren-bucket-for-richh-2/pretrained-model/20180402-114759.pb\n",
      "\n",
      "training-yymFH-_ig: INFO:__main__:Processing iteration 0 batch of size: 128\n",
      "\n",
      "training-yymFH-_ig: \n",
      "training-yymFH-_ig: INFO:__main__:Processing iteration 1 batch of size: 128\n",
      "\n",
      "training-yymFH-_ig: INFO:__main__:Processing iteration 2 batch of size: 2\n",
      "\n",
      "training-yymFH-_ig: INFO:__main__:Created 258 embeddings\n",
      "\n",
      "training-yymFH-_ig: INFO:__main__:Evaluating classifier on 258 images\n",
      "\n",
      "training-yymFH-_ig: INFO:__main__:Testing completed in 5.181173324584961 seconds\n",
      "\n",
      "training-yymFH-_ig:    0  Prediction: Ann_Veneman, Confidence: 0.341, Actual: Ann_Veneman\n",
      "\n",
      "training-yymFH-_ig:    1  Prediction: George_W_Bush, Confidence: 0.999, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:    2  Prediction: Amelie_Mauresmo, Confidence: 0.252, Actual: Alejandro_Toledo\n",
      "\n",
      "training-yymFH-_ig:    3  Prediction: George_W_Bush, Confidence: 0.308, Actual: Amelie_Mauresmo\n",
      "\n",
      "training-yymFH-_ig:    4  Prediction: George_W_Bush, Confidence: 0.992, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:    5  Prediction: George_W_Bush, Confidence: 0.998, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:    6  Prediction: George_W_Bush, Confidence: 0.995, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:    7  Prediction: Ariel_Sharon, Confidence: 0.842, Actual: Ariel_Sharon\n",
      "\n",
      "training-yymFH-_ig:    8  Prediction: George_W_Bush, Confidence: 0.992, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:    9  Prediction: Arnold_Schwarzenegger, Confidence: 0.972, Actual: Arnold_Schwarzenegger\n",
      "\n",
      "training-yymFH-_ig:   10  Prediction: Amelie_Mauresmo, Confidence: 0.497, Actual: Amelie_Mauresmo\n",
      "\n",
      "training-yymFH-_ig:   11  Prediction: Alvaro_Uribe, Confidence: 0.419, Actual: Alvaro_Uribe\n",
      "\n",
      "training-yymFH-_ig:   12  Prediction: Atal_Bihari_Vajpayee, Confidence: 0.731, Actual: Atal_Bihari_Vajpayee\n",
      "\n",
      "training-yymFH-_ig:   13  Prediction: George_W_Bush, Confidence: 0.909, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   14  Prediction: George_W_Bush, Confidence: 0.999, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   15  Prediction: Anna_Kournikova, Confidence: 0.876, Actual: Anna_Kournikova\n",
      "\n",
      "training-yymFH-_ig:   16  Prediction: Andre_Agassi, Confidence: 0.796, Actual: Andre_Agassi\n",
      "\n",
      "training-yymFH-_ig:   17  Prediction: George_W_Bush, Confidence: 0.999, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   18  Prediction: Amelie_Mauresmo, Confidence: 0.929, Actual: Amelie_Mauresmo\n",
      "\n",
      "training-yymFH-_ig:   19  Prediction: George_W_Bush, Confidence: 0.996, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   20  Prediction: George_W_Bush, Confidence: 0.998, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   21  Prediction: George_W_Bush, Confidence: 0.952, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   22  Prediction: George_W_Bush, Confidence: 0.993, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   23  Prediction: Alvaro_Uribe, Confidence: 0.925, Actual: Alvaro_Uribe\n",
      "\n",
      "training-yymFH-_ig:   24  Prediction: George_W_Bush, Confidence: 0.997, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   25  Prediction: George_W_Bush, Confidence: 0.999, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   26  Prediction: Ariel_Sharon, Confidence: 0.926, Actual: Ariel_Sharon\n",
      "\n",
      "training-yymFH-_ig:   27  Prediction: George_W_Bush, Confidence: 0.996, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   28  Prediction: Alvaro_Uribe, Confidence: 0.745, Actual: Alvaro_Uribe\n",
      "\n",
      "training-yymFH-_ig:   29  Prediction: Adrien_Brody, Confidence: 0.825, Actual: Adrien_Brody\n",
      "\n",
      "training-yymFH-_ig:   30  Prediction: Andre_Agassi, Confidence: 0.349, Actual: Atal_Bihari_Vajpayee\n",
      "\n",
      "training-yymFH-_ig:   31  Prediction: Ari_Fleischer, Confidence: 0.951, Actual: Ari_Fleischer\n",
      "\n",
      "training-yymFH-_ig:   32  Prediction: Alvaro_Uribe, Confidence: 0.840, Actual: Alvaro_Uribe\n",
      "\n",
      "training-yymFH-_ig:   33  Prediction: Alejandro_Toledo, Confidence: 0.989, Actual: Alejandro_Toledo\n",
      "\n",
      "training-yymFH-_ig:   34  Prediction: George_W_Bush, Confidence: 0.994, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   35  Prediction: George_W_Bush, Confidence: 0.973, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   36  Prediction: Ariel_Sharon, Confidence: 0.987, Actual: Ariel_Sharon\n",
      "\n",
      "training-yymFH-_ig:   37  Prediction: George_W_Bush, Confidence: 0.988, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   38  Prediction: George_W_Bush, Confidence: 0.995, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   39  Prediction: George_W_Bush, Confidence: 0.957, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   40  Prediction: Atal_Bihari_Vajpayee, Confidence: 0.965, Actual: Atal_Bihari_Vajpayee\n",
      "\n",
      "training-yymFH-_ig:   41  Prediction: Arnold_Schwarzenegger, Confidence: 0.416, Actual: Arnold_Schwarzenegger\n",
      "\n",
      "training-yymFH-_ig:   42  Prediction: Ariel_Sharon, Confidence: 0.984, Actual: Ariel_Sharon\n",
      "\n",
      "training-yymFH-_ig:   43  Prediction: Andre_Agassi, Confidence: 0.992, Actual: Andre_Agassi\n",
      "\n",
      "training-yymFH-_ig:   44  Prediction: Ariel_Sharon, Confidence: 0.986, Actual: Ariel_Sharon\n",
      "\n",
      "training-yymFH-_ig:   45  Prediction: George_W_Bush, Confidence: 0.997, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   46  Prediction: George_W_Bush, Confidence: 0.682, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   47  Prediction: George_W_Bush, Confidence: 0.987, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   48  Prediction: George_W_Bush, Confidence: 0.995, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   49  Prediction: George_W_Bush, Confidence: 0.996, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   50  Prediction: George_W_Bush, Confidence: 0.996, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   51  Prediction: Alejandro_Toledo, Confidence: 0.501, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   52  Prediction: Ariel_Sharon, Confidence: 0.990, Actual: Ariel_Sharon\n",
      "\n",
      "training-yymFH-_ig:   53  Prediction: George_W_Bush, Confidence: 0.996, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   54  Prediction: Ariel_Sharon, Confidence: 0.988, Actual: Ariel_Sharon\n",
      "\n",
      "training-yymFH-_ig:   55  Prediction: George_W_Bush, Confidence: 0.995, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   56  Prediction: George_W_Bush, Confidence: 0.999, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   57  Prediction: Atal_Bihari_Vajpayee, Confidence: 0.425, Actual: Atal_Bihari_Vajpayee\n",
      "\n",
      "training-yymFH-_ig:   58  Prediction: Andre_Agassi, Confidence: 0.963, Actual: Andre_Agassi\n",
      "\n",
      "training-yymFH-_ig:   59  Prediction: George_W_Bush, Confidence: 0.995, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   60  Prediction: Andre_Agassi, Confidence: 0.972, Actual: Andre_Agassi\n",
      "\n",
      "training-yymFH-_ig:   61  Prediction: George_W_Bush, Confidence: 0.987, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   62  Prediction: Arnold_Schwarzenegger, Confidence: 0.951, Actual: Arnold_Schwarzenegger\n",
      "\n",
      "training-yymFH-_ig:   63  Prediction: George_W_Bush, Confidence: 0.997, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   64  Prediction: Angelina_Jolie, Confidence: 0.913, Actual: Angelina_Jolie\n",
      "\n",
      "training-yymFH-_ig:   65  Prediction: Alejandro_Toledo, Confidence: 0.527, Actual: Alejandro_Toledo\n",
      "\n",
      "training-yymFH-_ig:   66  Prediction: Alejandro_Toledo, Confidence: 0.691, Actual: Adrien_Brody\n",
      "\n",
      "training-yymFH-_ig:   67  Prediction: Ariel_Sharon, Confidence: 0.983, Actual: Ariel_Sharon\n",
      "\n",
      "training-yymFH-_ig:   68  Prediction: George_W_Bush, Confidence: 0.995, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   69  Prediction: George_W_Bush, Confidence: 0.999, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   70  Prediction: George_W_Bush, Confidence: 0.989, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   71  Prediction: George_W_Bush, Confidence: 0.999, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   72  Prediction: George_W_Bush, Confidence: 0.996, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   73  Prediction: Ann_Veneman, Confidence: 0.861, Actual: Ann_Veneman\n",
      "\n",
      "training-yymFH-_ig:   74  Prediction: Abdullah_Gul, Confidence: 0.693, Actual: Abdullah_Gul\n",
      "\n",
      "training-yymFH-_ig:   75  Prediction: George_W_Bush, Confidence: 0.994, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   76  Prediction: Alejandro_Toledo, Confidence: 0.955, Actual: Alejandro_Toledo\n",
      "\n",
      "training-yymFH-_ig:   77  Prediction: George_W_Bush, Confidence: 0.995, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   78  Prediction: George_W_Bush, Confidence: 0.999, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   79  Prediction: George_W_Bush, Confidence: 0.988, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   80  Prediction: Abdullah_Gul, Confidence: 0.888, Actual: Abdullah_Gul\n",
      "\n",
      "training-yymFH-_ig:   81  Prediction: George_W_Bush, Confidence: 0.984, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   82  Prediction: George_W_Bush, Confidence: 0.994, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   83  Prediction: George_W_Bush, Confidence: 0.999, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   84  Prediction: George_W_Bush, Confidence: 0.996, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   85  Prediction: George_W_Bush, Confidence: 0.925, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   86  Prediction: George_W_Bush, Confidence: 0.991, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   87  Prediction: George_W_Bush, Confidence: 0.998, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   88  Prediction: George_W_Bush, Confidence: 0.998, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   89  Prediction: George_W_Bush, Confidence: 0.993, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   90  Prediction: Angelina_Jolie, Confidence: 0.854, Actual: Angelina_Jolie\n",
      "\n",
      "training-yymFH-_ig:   91  Prediction: George_W_Bush, Confidence: 0.980, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   92  Prediction: George_W_Bush, Confidence: 0.994, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   93  Prediction: Ariel_Sharon, Confidence: 0.792, Actual: Ariel_Sharon\n",
      "\n",
      "training-yymFH-_ig:   94  Prediction: George_W_Bush, Confidence: 0.999, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   95  Prediction: Ari_Fleischer, Confidence: 0.782, Actual: Ari_Fleischer\n",
      "\n",
      "training-yymFH-_ig:   96  Prediction: George_W_Bush, Confidence: 0.999, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   97  Prediction: George_W_Bush, Confidence: 0.998, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:   98  Prediction: Atal_Bihari_Vajpayee, Confidence: 0.720, Actual: Atal_Bihari_Vajpayee\n",
      "\n",
      "training-yymFH-_ig:   99  Prediction: Ariel_Sharon, Confidence: 0.981, Actual: Ariel_Sharon\n",
      "\n",
      "training-yymFH-_ig:  100  Prediction: Abdullah_Gul, Confidence: 0.673, Actual: Abdullah_Gul\n",
      "\n",
      "training-yymFH-_ig:  101  Prediction: Andre_Agassi, Confidence: 0.766, Actual: Andre_Agassi\n",
      "\n",
      "training-yymFH-_ig:  102  Prediction: Abdullah_Gul, Confidence: 0.890, Actual: Abdullah_Gul\n",
      "\n",
      "training-yymFH-_ig:  103  Prediction: George_W_Bush, Confidence: 0.999, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  104  Prediction: George_W_Bush, Confidence: 0.995, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  105  Prediction: Alejandro_Toledo, Confidence: 0.900, Actual: Alejandro_Toledo\n",
      "\n",
      "training-yymFH-_ig:  106  Prediction: Andre_Agassi, Confidence: 0.521, Actual: Andre_Agassi\n",
      "\n",
      "training-yymFH-_ig:  107  Prediction: Angelina_Jolie, Confidence: 0.762, Actual: Angelina_Jolie\n",
      "\n",
      "training-yymFH-_ig:  108  Prediction: George_W_Bush, Confidence: 0.999, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  109  Prediction: George_W_Bush, Confidence: 0.998, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  110  Prediction: George_W_Bush, Confidence: 0.999, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  111  Prediction: George_W_Bush, Confidence: 0.994, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  112  Prediction: Adrien_Brody, Confidence: 0.740, Actual: Adrien_Brody\n",
      "\n",
      "training-yymFH-_ig:  113  Prediction: Arnold_Schwarzenegger, Confidence: 0.576, Actual: Arnold_Schwarzenegger\n",
      "\n",
      "training-yymFH-_ig:  114  Prediction: George_W_Bush, Confidence: 0.995, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  115  Prediction: George_W_Bush, Confidence: 0.993, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  116  Prediction: George_W_Bush, Confidence: 0.999, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  117  Prediction: George_W_Bush, Confidence: 0.999, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  118  Prediction: George_W_Bush, Confidence: 0.998, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  119  Prediction: Angelina_Jolie, Confidence: 0.869, Actual: Angelina_Jolie\n",
      "\n",
      "training-yymFH-_ig:  120  Prediction: George_W_Bush, Confidence: 0.968, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  121  Prediction: Andre_Agassi, Confidence: 0.990, Actual: Andre_Agassi\n",
      "\n",
      "training-yymFH-_ig:  122  Prediction: Alvaro_Uribe, Confidence: 0.977, Actual: Alvaro_Uribe\n",
      "\n",
      "training-yymFH-_ig:  123  Prediction: George_W_Bush, Confidence: 0.992, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  124  Prediction: George_W_Bush, Confidence: 0.986, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  125  Prediction: George_W_Bush, Confidence: 0.993, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  126  Prediction: George_W_Bush, Confidence: 0.993, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  127  Prediction: Arnold_Schwarzenegger, Confidence: 0.637, Actual: Arnold_Schwarzenegger\n",
      "\n",
      "training-yymFH-_ig:  128  Prediction: George_W_Bush, Confidence: 0.999, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  129  Prediction: Andy_Roddick, Confidence: 0.706, Actual: Andy_Roddick\n",
      "\n",
      "training-yymFH-_ig:  130  Prediction: George_W_Bush, Confidence: 0.999, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  131  Prediction: Alvaro_Uribe, Confidence: 0.722, Actual: Alvaro_Uribe\n",
      "\n",
      "training-yymFH-_ig:  132  Prediction: George_W_Bush, Confidence: 0.999, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  133  Prediction: George_W_Bush, Confidence: 0.775, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  134  Prediction: Alejandro_Toledo, Confidence: 0.956, Actual: Alejandro_Toledo\n",
      "\n",
      "training-yymFH-_ig:  142  Prediction: George_W_Bush, Confidence: 0.917, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  143  Prediction: Ari_Fleischer, Confidence: 0.945, Actual: Ari_Fleischer\n",
      "\n",
      "training-yymFH-_ig:  144  Prediction: George_W_Bush, Confidence: 0.941, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  145  Prediction: George_W_Bush, Confidence: 0.996, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  146  Prediction: George_W_Bush, Confidence: 0.998, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  147  Prediction: George_W_Bush, Confidence: 0.999, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  148  Prediction: Alvaro_Uribe, Confidence: 0.954, Actual: Alvaro_Uribe\n",
      "\n",
      "training-yymFH-_ig:  149  Prediction: George_W_Bush, Confidence: 0.998, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  153  Prediction: George_W_Bush, Confidence: 0.997, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  154  Prediction: George_W_Bush, Confidence: 0.986, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  155  Prediction: Andre_Agassi, Confidence: 0.924, Actual: Andre_Agassi\n",
      "\n",
      "training-yymFH-_ig:  156  Prediction: George_W_Bush, Confidence: 0.998, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  157  Prediction: Amelie_Mauresmo, Confidence: 0.770, Actual: Andy_Roddick\n",
      "\n",
      "training-yymFH-_ig:  158  Prediction: Atal_Bihari_Vajpayee, Confidence: 0.846, Actual: Atal_Bihari_Vajpayee\n",
      "\n",
      "training-yymFH-_ig:  159  Prediction: Alvaro_Uribe, Confidence: 0.969, Actual: Alvaro_Uribe\n",
      "\n",
      "training-yymFH-_ig:  160  Prediction: George_W_Bush, Confidence: 0.997, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  161  Prediction: George_W_Bush, Confidence: 0.998, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  162  Prediction: George_W_Bush, Confidence: 0.989, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  163  Prediction: Arnold_Schwarzenegger, Confidence: 0.816, Actual: Arnold_Schwarzenegger\n",
      "\n",
      "training-yymFH-_ig:  164  Prediction: Abdullah_Gul, Confidence: 0.797, Actual: Abdullah_Gul\n",
      "\n",
      "training-yymFH-_ig: \n",
      "training-yymFH-_ig:  165  Prediction: Andre_Agassi, Confidence: 0.964, Actual: Andre_Agassi\n",
      "\n",
      "training-yymFH-_ig:  166  Prediction: George_W_Bush, Confidence: 0.999, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  167  Prediction: George_W_Bush, Confidence: 0.999, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  168  Prediction: Alvaro_Uribe, Confidence: 0.989, Actual: Alvaro_Uribe\n",
      "\n",
      "training-yymFH-_ig:  169  Prediction: Anna_Kournikova, Confidence: 0.233, Actual: Anna_Kournikova\n",
      "\n",
      "training-yymFH-_ig:  170  Prediction: George_W_Bush, Confidence: 0.997, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  171  Prediction: Amelie_Mauresmo, Confidence: 0.437, Actual: Amelie_Mauresmo\n",
      "\n",
      "training-yymFH-_ig:  172  Prediction: Ariel_Sharon, Confidence: 0.992, Actual: Ariel_Sharon\n",
      "\n",
      "training-yymFH-_ig:  173  Prediction: Ariel_Sharon, Confidence: 0.832, Actual: Ariel_Sharon\n",
      "\n",
      "training-yymFH-_ig:  174  Prediction: George_W_Bush, Confidence: 0.962, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  175  Prediction: Ariel_Sharon, Confidence: 0.988, Actual: Ariel_Sharon\n",
      "\n",
      "training-yymFH-_ig:  176  Prediction: Ariel_Sharon, Confidence: 0.974, Actual: Ariel_Sharon\n",
      "\n",
      "training-yymFH-_ig:  177  Prediction: George_W_Bush, Confidence: 0.997, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  178  Prediction: George_W_Bush, Confidence: 0.998, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  179  Prediction: George_W_Bush, Confidence: 0.992, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  180  Prediction: Arnold_Schwarzenegger, Confidence: 0.969, Actual: Arnold_Schwarzenegger\n",
      "\n",
      "training-yymFH-_ig:  181  Prediction: George_W_Bush, Confidence: 0.999, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  182  Prediction: Ariel_Sharon, Confidence: 0.984, Actual: Ariel_Sharon\n",
      "\n",
      "training-yymFH-_ig:  183  Prediction: Arnold_Schwarzenegger, Confidence: 0.779, Actual: Arnold_Schwarzenegger\n",
      "\n",
      "training-yymFH-_ig:  184  Prediction: George_W_Bush, Confidence: 0.970, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  185  Prediction: Ann_Veneman, Confidence: 0.536, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  186  Prediction: George_W_Bush, Confidence: 0.995, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  187  Prediction: Alejandro_Toledo, Confidence: 0.816, Actual: Alejandro_Toledo\n",
      "\n",
      "training-yymFH-_ig:  188  Prediction: George_W_Bush, Confidence: 0.995, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  189  Prediction: Alejandro_Toledo, Confidence: 0.909, Actual: Alejandro_Toledo\n",
      "\n",
      "training-yymFH-_ig:  190  Prediction: Angelina_Jolie, Confidence: 0.902, Actual: Angelina_Jolie\n",
      "\n",
      "training-yymFH-_ig:  191  Prediction: George_W_Bush, Confidence: 0.987, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  192  Prediction: Alejandro_Toledo, Confidence: 0.810, Actual: Alejandro_Toledo\n",
      "\n",
      "training-yymFH-_ig:  193  Prediction: Andre_Agassi, Confidence: 0.958, Actual: Andre_Agassi\n",
      "\n",
      "training-yymFH-_ig:  194  Prediction: George_W_Bush, Confidence: 0.991, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  195  Prediction: Ariel_Sharon, Confidence: 0.994, Actual: Ariel_Sharon\n",
      "\n",
      "training-yymFH-_ig:  196  Prediction: Ariel_Sharon, Confidence: 0.992, Actual: Ariel_Sharon\n",
      "\n",
      "training-yymFH-_ig:  197  Prediction: Ariel_Sharon, Confidence: 0.990, Actual: Ariel_Sharon\n",
      "\n",
      "training-yymFH-_ig:  198  Prediction: Alejandro_Toledo, Confidence: 0.786, Actual: Alejandro_Toledo\n",
      "\n",
      "training-yymFH-_ig:  199  Prediction: George_W_Bush, Confidence: 1.000, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  200  Prediction: George_W_Bush, Confidence: 0.938, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  201  Prediction: George_W_Bush, Confidence: 0.998, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  202  Prediction: George_W_Bush, Confidence: 0.998, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  203  Prediction: George_W_Bush, Confidence: 0.985, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  204  Prediction: George_W_Bush, Confidence: 0.991, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  205  Prediction: George_W_Bush, Confidence: 0.906, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  206  Prediction: George_W_Bush, Confidence: 0.997, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  207  Prediction: George_W_Bush, Confidence: 0.989, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  208  Prediction: George_W_Bush, Confidence: 0.998, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  209  Prediction: Amelie_Mauresmo, Confidence: 0.690, Actual: Amelie_Mauresmo\n",
      "\n",
      "training-yymFH-_ig:  210  Prediction: George_W_Bush, Confidence: 0.937, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  211  Prediction: George_W_Bush, Confidence: 0.998, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  212  Prediction: George_W_Bush, Confidence: 0.999, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  213  Prediction: George_W_Bush, Confidence: 0.982, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  214  Prediction: George_W_Bush, Confidence: 0.998, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  215  Prediction: George_W_Bush, Confidence: 0.999, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  216  Prediction: George_W_Bush, Confidence: 1.000, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  217  Prediction: Arnold_Schwarzenegger, Confidence: 0.641, Actual: Arnold_Schwarzenegger\n",
      "\n",
      "training-yymFH-_ig:  218  Prediction: George_W_Bush, Confidence: 0.928, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  219  Prediction: George_W_Bush, Confidence: 0.996, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  220  Prediction: George_W_Bush, Confidence: 0.999, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  221  Prediction: George_W_Bush, Confidence: 0.980, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  222  Prediction: George_W_Bush, Confidence: 0.997, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  223  Prediction: George_W_Bush, Confidence: 0.999, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  224  Prediction: George_W_Bush, Confidence: 0.999, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  225  Prediction: George_W_Bush, Confidence: 0.999, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  226  Prediction: George_W_Bush, Confidence: 0.997, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  227  Prediction: George_W_Bush, Confidence: 1.000, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  228  Prediction: Arnold_Schwarzenegger, Confidence: 0.278, Actual: Arnold_Schwarzenegger\n",
      "\n",
      "training-yymFH-_ig:  229  Prediction: George_W_Bush, Confidence: 0.998, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  230  Prediction: George_W_Bush, Confidence: 0.999, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  231  Prediction: Alejandro_Toledo, Confidence: 0.957, Actual: Alejandro_Toledo\n",
      "\n",
      "training-yymFH-_ig:  232  Prediction: George_W_Bush, Confidence: 0.922, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  233  Prediction: George_W_Bush, Confidence: 0.997, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  234  Prediction: George_W_Bush, Confidence: 0.741, Actual: Arnold_Schwarzenegger\n",
      "\n",
      "training-yymFH-_ig:  235  Prediction: George_W_Bush, Confidence: 0.998, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  236  Prediction: George_W_Bush, Confidence: 0.999, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  237  Prediction: George_W_Bush, Confidence: 0.992, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  238  Prediction: George_W_Bush, Confidence: 0.999, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  239  Prediction: George_W_Bush, Confidence: 0.999, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  240  Prediction: Andy_Roddick, Confidence: 0.365, Actual: Andy_Roddick\n",
      "\n",
      "training-yymFH-_ig:  241  Prediction: Arnold_Schwarzenegger, Confidence: 0.900, Actual: Arnold_Schwarzenegger\n",
      "\n",
      "training-yymFH-_ig:  242  Prediction: Ariel_Sharon, Confidence: 0.970, Actual: Ariel_Sharon\n",
      "\n",
      "training-yymFH-_ig:  243  Prediction: George_W_Bush, Confidence: 0.999, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  244  Prediction: George_W_Bush, Confidence: 0.999, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  245  Prediction: George_W_Bush, Confidence: 0.998, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  246  Prediction: Ariel_Sharon, Confidence: 0.988, Actual: Ariel_Sharon\n",
      "\n",
      "training-yymFH-_ig:  247  Prediction: George_W_Bush, Confidence: 0.999, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  248  Prediction: Ariel_Sharon, Confidence: 0.954, Actual: Ariel_Sharon\n",
      "\n",
      "training-yymFH-_ig:  249  Prediction: George_W_Bush, Confidence: 0.984, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  250  Prediction: George_W_Bush, Confidence: 0.990, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  251  Prediction: George_W_Bush, Confidence: 0.998, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  252  Prediction: George_W_Bush, Confidence: 0.995, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  253  Prediction: George_W_Bush, Confidence: 1.000, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  254  Prediction: George_W_Bush, Confidence: 0.993, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  255  Prediction: George_W_Bush, Confidence: 0.997, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  256  Prediction: George_W_Bush, Confidence: 0.999, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig:  257  Prediction: George_W_Bush, Confidence: 0.996, Actual: George_W_Bush\n",
      "\n",
      "training-yymFH-_ig: Accuracy: 0.969\n",
      "\n",
      "training-yymFH-_ig: \n",
      "training-yymFH-_ig: \n",
      "training-yymFH-_ig: \n",
      "training-yymFH-_ig: \n",
      "training-yymFH-_ig: \n",
      "training-yymFH-_ig: \n",
      "training-yymFH-_ig: \n",
      "training-yymFH-_ig: \n",
      "training-yymFH-_ig: \n",
      "training-yymFH-_ig: \n",
      "\n",
      "\n",
      "-----------------\n",
      "Log monitor done.\n",
      "-----------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "client.training.monitor_logs(training_run_guid_async)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: You can cancel the training run by calling the method `client.training.cancel(training_run_guid_async)`\n",
    "\n",
    "After the training is complete, get the training GUID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training GUID is: training-yymFH-_ig\n"
     ]
    }
   ],
   "source": [
    "training_details = client.training.get_details(training_run_guid_async)\n",
    "training_guid = training_details[\"entity\"][\"training_results_reference\"][\"location\"][\"model_location\"]\n",
    "print(\"Training GUID is:\", training_guid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"work\"></a>\n",
    "## <span style=\"color:blue\">8. Work with the Trained Model</span>\n",
    "\n",
    "After the training is complete, the trained model is saved as a file named\n",
    "`output-classifier.pkl` in the result bucket.\n",
    "The following code will fetch the model file from the bucket.\n",
    "\n",
    "**Tip:** Make sure that the training run is completed by checking its\n",
    "status as shown earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_obj = cos.Bucket(BUCKET)\n",
    "\n",
    "# Trained model file name as defined in the code.\n",
    "saved_model_filename = \"output-classifier.pkl\"\n",
    "source_file = os.path.join(training_guid, saved_model_filename)\n",
    "bucket_obj.download_file(source_file,saved_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openface\t       pretrained-model  pywren-ibm-cloud.zip\r\n",
      "output-classifier.pkl  pywren-ibm-cloud  tf-facial-recog.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use model to classify images\n",
    "\n",
    "We are going to use parts of the code that we used with WML to classify images using our trained classifier. Typically we'd want to run the sample image through the same preprocessing steps we used on the training images (face alignment), however we get decent performance just resizing the input images. So let's set that up now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import gfile\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Use the pretrained model we downloaded previously.\n",
    "model_path = './pretrained-model/20180402-114759/20180402-114759.pb'\n",
    "\n",
    "# The trained classifier we downloaded from our COS bucket after training.\n",
    "classifier_path = 'output-classifier.pkl'\n",
    "\n",
    "\n",
    "def run_model(image_paths):\n",
    "    with tf.Session(config=tf.ConfigProto(log_device_placement=False)) as sess:\n",
    "        _load_model(model_filepath=model_path)\n",
    "\n",
    "        dataset = tf.contrib.data.Dataset.from_tensor_slices((image_paths)) \\\n",
    "                .map(_preprocess_function) \\\n",
    "                .batch(128)\n",
    "\n",
    "        init_op = tf.group(tf.global_variables_initializer(),\n",
    "                           tf.local_variables_initializer())\n",
    "        sess.run(init_op)\n",
    "\n",
    "        iterator = dataset.make_one_shot_iterator()\n",
    "        batch = iterator.get_next()\n",
    "        batch_images = sess.run(batch)\n",
    "\n",
    "        images_placeholder = \\\n",
    "            tf.get_default_graph().get_tensor_by_name(\"input:0\")\n",
    "        embedding_layer = \\\n",
    "            tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")\n",
    "        phase_train_placeholder = \\\n",
    "            tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")\n",
    "\n",
    "        emb = sess.run(embedding_layer,\n",
    "                feed_dict={images_placeholder: batch_images,\n",
    "                           phase_train_placeholder: False})\n",
    "\n",
    "        with open(classifier_path, 'rb') as f:\n",
    "            model, class_names = pickle.load(f)\n",
    "\n",
    "            predictions = model.predict_proba(emb, )\n",
    "            for index, prediction in enumerate(predictions):\n",
    "                # Display the image in the notebook.\n",
    "                img = Image.open(image_paths[index])\n",
    "                img.thumbnail((100, 100))\n",
    "                display(img)\n",
    "\n",
    "                # Get the indices that would sort the array, then only get the\n",
    "                # indices that correspond to the top 3 predictions.\n",
    "                sorted_indices = prediction.argsort()[::-1][:3]\n",
    "                for index in sorted_indices:\n",
    "                    label = class_names[index]\n",
    "                    confidence = prediction[index]\n",
    "                    print('%s (confidence = %.5f)' % (label, confidence))\n",
    "                print('------------')\n",
    "\n",
    "\n",
    "def _preprocess_function(image_path):\n",
    "    file_contents = tf.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(file_contents, channels=3)\n",
    "    image = tf.image.resize_images([image], (300, 300))[0]\n",
    "    image = tf.image.resize_image_with_crop_or_pad(image, 160, 160)\n",
    "    image = tf.image.per_image_standardization(image)\n",
    "    return image\n",
    "\n",
    "\n",
    "def _load_model(model_filepath):\n",
    "    model_exp = os.path.expanduser(model_filepath)\n",
    "    if os.path.isfile(model_exp):\n",
    "        with gfile.FastGFile(model_exp, 'rb') as f:\n",
    "            graph_def = tf.GraphDef()\n",
    "            graph_def.ParseFromString(f.read())\n",
    "            tf.import_graph_def(graph_def, name='')\n",
    "    else:\n",
    "        raise Exception('Specified model %s is not a file.' % (model_exp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download some sample images\n",
    "\n",
    "Now, we are going to download some sample images that we can run through the model, so feel free to add other URLs to the list below. Just make sure they are JPEG images. Since we aren't doing the facial alignment preprocessing for this step, pictures where the faces are more prominent work better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_images_dir = './sample-images'\n",
    "image_urls = [\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/b/b3/Adrien_Brody_Cannes_2017.jpg',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/thumb/0/0c/SchwarzeneggerJan2010.jpg/800px-SchwarzeneggerJan2010.jpg'       \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./sample-images/sample0.jpg', './sample-images/sample1.jpg']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wget\n",
    "\n",
    "if not os.path.exists(sample_images_dir):\n",
    "    os.makedirs(sample_images_dir)\n",
    "\n",
    "images = []\n",
    "for index, url in enumerate(image_urls):\n",
    "    outfile = os.path.join(sample_images_dir, 'sample{}.jpg'.format(index))\n",
    "    images.append(outfile)\n",
    "    wget.download(url, out=outfile)\n",
    "\n",
    "print(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run classifier on images\n",
    "\n",
    "Now that we downloaded some images, let's try classifying them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=67x100 at 0x7FC0A5CEDFD0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adrien_Brody (confidence = 0.43051)\n",
      "Alvaro_Uribe (confidence = 0.22949)\n",
      "Alejandro_Toledo (confidence = 0.08655)\n",
      "------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=70x100 at 0x7FC0A5C821D0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arnold_Schwarzenegger (confidence = 0.94769)\n",
      "George_W_Bush (confidence = 0.02411)\n",
      "Adrien_Brody (confidence = 0.00877)\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "run_model(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"summary\"></a>\n",
    "## <span style=\"color:blue\"> 9. Summary</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we used PyWren with IBM Cloud Functions to increase preprocessing performance and stored the resulting images in an IBM Cloud Object Storage bucket. From here, we used this bucket along with IBM Watson Machine Learning to create embeddings of each identity using a pretrained TensorFlow FaceNet model, and then created a custom face classifer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citations\n",
    "\n",
    "Q. Cao, L. Shen, W. Xie, O. M. Parkhi, A. Zisserman. \"VGGFace2: A dataset for recognising face across pose and age\"  International Conference on Automatic Face and Gesture Recognition, 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "1. <a href=\"https://hackernoon.com/building-a-facial-recognition-pipeline-with-deep-learning-in-tensorflow-66e7645015b8\" target=\"_blank\" rel=\"noopener no referrer\">Building a Facial Recognition Pipeline with Deep Learning in Tensorflow</a> (Original inspiration for code pattern)\n",
    "2. <a href=\"https://github.com/davidsandberg/facenet\" target=\"_blank\" rel=\"noopener no referrer\">Face Recognition using Tensorflow</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors\n",
    "\n",
    "**Gil Vernik**\n",
    "\n",
    "**Paul Van Eck**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © 2019 IBM. This notebook and its source code are released under the terms of the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#F5F7FA; height:110px; padding: 2em; font-size:14px;\">\n",
    "<span style=\"font-size:18px;color:#152935;\">Love this notebook? </span>\n",
    "<span style=\"font-size:15px;color:#152935;float:right;margin-right:40px;\">Don't have an account yet?</span><br>\n",
    "<span style=\"color:#5A6872;\">Share it with your colleagues and help them discover the power of Watson Studio!</span>\n",
    "<span style=\"border: 1px solid #3d70b2;padding:8px;float:right;margin-right:40px; color:#3d70b2;\"><a href=\"https://ibm.co/wsnotebooks\" target=\"_blank\" style=\"color: #3d70b2;text-decoration: none;\">Sign Up</a></span><br>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
